{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "from src.hog.hog import test_hog, load_hog\n",
    "from src.hog.hog_op import compute_hog_character\n",
    "\n",
    "from src.utils.load_data import get_test_data\n",
    "from src.utils.char_to_int import convert_int_to_char, convert_char_to_int\n",
    "\n",
    "from src.nn.model import CaptchaClassifierBigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_test_data()\n",
    "\n",
    "test_images_ground_truth_files = sorted(glob.glob('./dados/teste/*.jpg'))\n",
    "test_images_ground_truth = [cv2.imread(img, cv2.IMREAD_GRAYSCALE) for img in test_images_ground_truth_files ]\n",
    "\n",
    "test_label_files = sorted(glob.glob('./dados/labels10k/*.txt'))[9000:]\n",
    "test_labels = [open(label_file).read().strip() for label_file in test_label_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_classifier_path = 'models/captcha_classifier_hog.pkl'\n",
    "classifier = load_hog(hog_classifier_path)\n",
    "\n",
    "accuracy = test_hog(classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_hog(idx_image):\n",
    "    offset = 6 * idx_image\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(6):\n",
    "        features = compute_hog_character(X_test[i+offset])\n",
    "        features = features.reshape(1, -1)\n",
    "        pred = classifier.predict(features)\n",
    "        preds.append(pred[0])\n",
    "            \n",
    "    pred_string = ''.join(preds)\n",
    "    print(\"Predictions:\", pred_string)\n",
    "    print(\"Ground Truth label: \", test_labels[offset//6])\n",
    "    \n",
    "    num_errors = 0\n",
    "    for i in range(len(pred_string)):\n",
    "        if pred_string[i] != test_labels[offset//6][i]:\n",
    "            num_errors += 1\n",
    "\n",
    "    if not num_errors:\n",
    "        print('Acertou todos')\n",
    "    else:\n",
    "        print(f'Errou {num_errors} vezes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hog(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaptchaClassifierBigger()\n",
    "model.load_state_dict(torch.load('models/nn_model_bigger.pth'))\n",
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def results_nn(idx_image):\n",
    "    offset = 6 * idx_image\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    ax1 = plt.subplot2grid((2, 1), (0, 0), rowspan=1)\n",
    "    ax1.imshow(test_images_ground_truth[offset//6], cmap='gray')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot2grid((2, 6), (1, i))\n",
    "        ax.imshow(X_test[i+offset], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tensor = transform(X_test[i+offset]).to('cuda')\n",
    "            outputs = model(tensor.unsqueeze(0))\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            char_pred = convert_int_to_char(int(pred))\n",
    "            preds.append(char_pred)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('./images/ground_truth_vs_filtered.png', bbox_inches='tight')\n",
    "    \n",
    "    pred_string = ''.join(preds)\n",
    "    print(\"Predictions:\", pred_string)\n",
    "    print(\"Ground Truth label: \", test_labels[offset//6])\n",
    "    \n",
    "    num_errors = 0\n",
    "    for i in range(len(pred_string)):\n",
    "        if pred_string[i] != test_labels[offset//6][i]:\n",
    "            num_errors += 1\n",
    "\n",
    "    if not num_errors:\n",
    "        print('Acertou todos')\n",
    "    else:\n",
    "        print(f'Errou {num_errors} vezes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn(315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy by number of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hog(data):\n",
    "    features = compute_hog_character(data)\n",
    "    features = features.reshape(1, -1)\n",
    "    pred = classifier.predict(features)\n",
    "    return pred[0]\n",
    "\n",
    "def predict_nn(data):\n",
    "    tensor = transform(data).to('cuda')\n",
    "    outputs = model(tensor.unsqueeze(0))\n",
    "    _, pred = torch.max(outputs, 1)\n",
    "    char_pred = convert_int_to_char(int(pred))\n",
    "    return char_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_num_digits(predict_function):\n",
    "    \n",
    "    accuracies = []\n",
    "    recognitions = []\n",
    "    \n",
    "    for num_digits in [1, 2, 3, 4, 5, 6]:\n",
    "        digit_acc = []\n",
    "        digit_recog = []\n",
    "        for idx in range(len(test_labels)):\n",
    "            offset = 6 * idx\n",
    "        \n",
    "            preds = []\n",
    "            num_errors = 0\n",
    "            recog = 1\n",
    "            \n",
    "            indices = list(range(num_digits))\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            for i in indices:\n",
    "                with torch.no_grad():\n",
    "                    pred = predict_function(X_test[i+offset])\n",
    "                    preds.append(pred)\n",
    "                    \n",
    "                    if pred != test_labels[offset//6][i]:\n",
    "                        num_errors += 1\n",
    "            \n",
    "            # if idx % 250 == 0:\n",
    "            #     ordered_label = ''.join(np.array(list(test_labels[offset//6]))[indices])\n",
    "            #     print(''.join(preds), ordered_label, num_errors, num_digits, test_labels[offset//6])\n",
    "            \n",
    "            digit_acc.append((1 - num_errors/num_digits) * 100)\n",
    "            \n",
    "            if num_errors > 0:\n",
    "                recog = 0\n",
    "                \n",
    "            digit_recog.append(recog)\n",
    "                    \n",
    "        accuracies.append(np.mean(digit_acc))\n",
    "        recognitions.append(np.sum(digit_recog)/len(test_labels))\n",
    "        \n",
    "    return accuracies, recognitions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_hog, recognitions_hog = accuracy_num_digits(predict_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_nn, recognitions_nn = accuracy_num_digits(predict_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_num_digits(accuracies_hog, accuracies_nn, feature):\n",
    "    x = [1, 2, 3, 4, 5, 6]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.lineplot(x=x, y=accuracies_hog, marker='o', label='HOG', color='blue')\n",
    "\n",
    "    sns.lineplot(x=x, y=accuracies_nn, marker='o', label='NN', color='orange')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.2f}%'))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'{feature} Comparison of HOG and NN Models by Number of Digits')\n",
    "    plt.xlabel('Number of Digits')\n",
    "    plt.ylabel(f'{feature} (%)')\n",
    "\n",
    "    plt.legend(title='Model')\n",
    "    \n",
    "    plt.savefig(f'./images/{feature}_hog_vs_nn.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_num_digits(accuracies_hog, accuracies_nn, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognitions_hog = recognition_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_num_digits(recognitions_hog, recognitions_nn, 'Recognition')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
